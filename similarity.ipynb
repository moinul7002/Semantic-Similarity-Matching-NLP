{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d81ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe24ca68",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Study Section 5 of Chapter 2 of NLTK online book, and try to reproduce the coding examples and try to use your own examples of wording to identify the synsets, hyponyms, hypernyms, and various semantic similarity between two words of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ac2aa",
   "metadata": {},
   "source": [
    "### 5.1 Synsets\n",
    "\n",
    "**Example from Book** \n",
    "\n",
    "Consider the sentence in (1). If we replace the word motorcar in (1) by automobile, to get (2), the meaning of the sentence stays pretty much the same:\n",
    "\t\n",
    "1. Benz is credited with the invention of the motorcar.\n",
    "2. Benz is credited with the invention of the automobile.\n",
    "\n",
    "Since everything else in the sentence has remained unchanged, we can conclude that the words motorcar and automobile have the same meaning, i.e. they are synonyms. We can explore these words with the help of WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e823f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a67b1021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43ec2c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'), Synset('automobile.v.01')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('automobile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234a83c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e3dc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ffe828e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he needs a car to get to work']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a4774b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('car.n.01.car'),\n",
       " Lemma('car.n.01.auto'),\n",
       " Lemma('car.n.01.automobile'),\n",
       " Lemma('car.n.01.machine'),\n",
       " Lemma('car.n.01.motorcar')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b49796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('car.n.01.automobile')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('car.n.01.automobile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b51772aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('car.n.01')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('car.n.01.automobile').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0016922b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('car.n.01.automobile').name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "919a9e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fdc953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'auto', 'automobile', 'machine', 'motorcar']\n",
      "['car', 'railcar', 'railway_car', 'railroad_car']\n",
      "['car', 'gondola']\n",
      "['car', 'elevator_car']\n",
      "['cable_car', 'car']\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('car'):\n",
    "    print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31c2248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('car.n.01.car'),\n",
       " Lemma('car.n.02.car'),\n",
       " Lemma('car.n.03.car'),\n",
       " Lemma('car.n.04.car'),\n",
       " Lemma('cable_car.n.01.car')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmas('car')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a628b",
   "metadata": {},
   "source": [
    "### 5.2 Hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee7e8303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('ambulance.n.01')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar = wn.synset('car.n.01')\n",
    "types_of_motorcar = motorcar.hyponyms()\n",
    "types_of_motorcar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60f7e30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model_T',\n",
       " 'S.U.V.',\n",
       " 'SUV',\n",
       " 'Stanley_Steamer',\n",
       " 'ambulance',\n",
       " 'beach_waggon',\n",
       " 'beach_wagon',\n",
       " 'bus',\n",
       " 'cab',\n",
       " 'compact',\n",
       " 'compact_car',\n",
       " 'convertible',\n",
       " 'coupe',\n",
       " 'cruiser',\n",
       " 'electric',\n",
       " 'electric_automobile',\n",
       " 'electric_car',\n",
       " 'estate_car',\n",
       " 'gas_guzzler',\n",
       " 'hack',\n",
       " 'hardtop',\n",
       " 'hatchback',\n",
       " 'heap',\n",
       " 'horseless_carriage',\n",
       " 'hot-rod',\n",
       " 'hot_rod',\n",
       " 'jalopy',\n",
       " 'jeep',\n",
       " 'landrover',\n",
       " 'limo',\n",
       " 'limousine',\n",
       " 'loaner',\n",
       " 'minicar',\n",
       " 'minivan',\n",
       " 'pace_car',\n",
       " 'patrol_car',\n",
       " 'phaeton',\n",
       " 'police_car',\n",
       " 'police_cruiser',\n",
       " 'prowl_car',\n",
       " 'race_car',\n",
       " 'racer',\n",
       " 'racing_car',\n",
       " 'roadster',\n",
       " 'runabout',\n",
       " 'saloon',\n",
       " 'secondhand_car',\n",
       " 'sedan',\n",
       " 'sport_car',\n",
       " 'sport_utility',\n",
       " 'sport_utility_vehicle',\n",
       " 'sports_car',\n",
       " 'squad_car',\n",
       " 'station_waggon',\n",
       " 'station_wagon',\n",
       " 'stock_car',\n",
       " 'subcompact',\n",
       " 'subcompact_car',\n",
       " 'taxi',\n",
       " 'taxicab',\n",
       " 'tourer',\n",
       " 'touring_car',\n",
       " 'two-seater',\n",
       " 'used-car',\n",
       " 'waggon',\n",
       " 'wagon']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lemma.name() for synset in types_of_motorcar for lemma in synset.lemmas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563771bb",
   "metadata": {},
   "source": [
    "### 5.3 Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f948dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('motor_vehicle.n.01')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e92ebb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = motorcar.hypernym_paths()\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "970e26f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'container.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d7812af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'conveyance.n.03',\n",
       " 'vehicle.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1c832e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.root_hypernyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa21ac2",
   "metadata": {},
   "source": [
    "### 5.4 Semantic Similariy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17c202db",
   "metadata": {},
   "outputs": [],
   "source": [
    "motorcar = wn.synset('car.n.01')\n",
    "automobile_1 = wn.synset('car.n.01')\n",
    "automobile_2 = wn.synset('automobile.v.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0298830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.lowest_common_hypernyms(automobile_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "966c4b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.lowest_common_hypernyms(automobile_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64ccd869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28eb1fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.path_similarity(automobile_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d55a6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.path_similarity(automobile_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe30bee",
   "metadata": {},
   "source": [
    "**Own Example**\n",
    "\n",
    "Let's use the WordNet library to identify synsets, hyponyms, hypernyms and measure semantic similarity between two words, \"dog\" and \"cat\".\n",
    "\n",
    "1. I have a pet dog.\n",
    "2. I have a pet cat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded9723",
   "metadata": {},
   "source": [
    "**Synsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe542c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e8be39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cat.n.01'),\n",
       " Synset('guy.n.01'),\n",
       " Synset('cat.n.03'),\n",
       " Synset('kat.n.01'),\n",
       " Synset('cat-o'-nine-tails.n.01'),\n",
       " Synset('caterpillar.n.02'),\n",
       " Synset('big_cat.n.01'),\n",
       " Synset('computerized_tomography.n.01'),\n",
       " Synset('cat.v.01'),\n",
       " Synset('vomit.v.01')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7396d3",
   "metadata": {},
   "source": [
    "**Hyponyms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09859ca7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('basenji.n.01'),\n",
       " Synset('corgi.n.01'),\n",
       " Synset('cur.n.01'),\n",
       " Synset('dalmatian.n.02'),\n",
       " Synset('great_pyrenees.n.01'),\n",
       " Synset('griffon.n.02'),\n",
       " Synset('hunting_dog.n.01'),\n",
       " Synset('lapdog.n.01'),\n",
       " Synset('leonberg.n.01'),\n",
       " Synset('mexican_hairless.n.01'),\n",
       " Synset('newfoundland.n.01'),\n",
       " Synset('pooch.n.01'),\n",
       " Synset('poodle.n.01'),\n",
       " Synset('pug.n.01'),\n",
       " Synset('puppy.n.01'),\n",
       " Synset('spitz.n.01'),\n",
       " Synset('toy_dog.n.01'),\n",
       " Synset('working_dog.n.01')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "types_of_dog = dog.hyponyms()\n",
    "types_of_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a541261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('domestic_cat.n.01'), Synset('wildcat.n.03')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = wn.synset('cat.n.01')\n",
    "types_of_cat = cat.hyponyms()\n",
    "types_of_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9bf05c",
   "metadata": {},
   "source": [
    "**Hypernyms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afaca277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c361047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('feline.n.01')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b58c2f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dog = dog.hypernym_paths()\n",
    "len(path_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24c1085a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_cat = cat.hypernym_paths()\n",
    "len(path_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d690d645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'living_thing.n.01',\n",
       " 'organism.n.01',\n",
       " 'animal.n.01',\n",
       " 'chordate.n.01',\n",
       " 'vertebrate.n.01',\n",
       " 'mammal.n.01',\n",
       " 'placental.n.01',\n",
       " 'carnivore.n.01',\n",
       " 'canine.n.02',\n",
       " 'dog.n.01']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in path_dog[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5696a670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'living_thing.n.01',\n",
       " 'organism.n.01',\n",
       " 'animal.n.01',\n",
       " 'domestic_animal.n.01',\n",
       " 'dog.n.01']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in path_dog[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "827c6d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'living_thing.n.01',\n",
       " 'organism.n.01',\n",
       " 'animal.n.01',\n",
       " 'chordate.n.01',\n",
       " 'vertebrate.n.01',\n",
       " 'mammal.n.01',\n",
       " 'placental.n.01',\n",
       " 'carnivore.n.01',\n",
       " 'feline.n.01',\n",
       " 'cat.n.01']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in path_cat[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f706e6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.root_hypernyms() #most general hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78fa2820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.root_hypernyms() #most general hypernyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb83664",
   "metadata": {},
   "source": [
    "**Semantic Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc3fbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a293715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb67d0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7f4643c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('carnivore.n.01')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.lowest_common_hypernyms(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f21c8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.path_similarity(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bced5b",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Identify the synsets of the word “car” and rank them in the order of their frequency of occurrence (most common synset first, less common synset at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d873a23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car = wn.synsets('car', 'n')\n",
    "car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7509fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('car.n.01.auto'), Lemma('car.n.01.automobile'), Lemma('car.n.01.car'), Lemma('car.n.01.machine'), Lemma('car.n.01.motorcar')]\n",
      "[Lemma('car.n.02.car'), Lemma('car.n.02.railcar'), Lemma('car.n.02.railroad_car'), Lemma('car.n.02.railway_car')]\n",
      "[Lemma('car.n.03.car'), Lemma('car.n.03.gondola')]\n",
      "[Lemma('car.n.04.car'), Lemma('car.n.04.elevator_car')]\n",
      "[Lemma('cable_car.n.01.cable_car'), Lemma('cable_car.n.01.car')]\n"
     ]
    }
   ],
   "source": [
    "for synset in car:\n",
    "    print(sorted(synset.lemmas()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1bd375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "synset_frequencies = [(synset, synset.lemmas()[0].count()) for synset in car]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1cb005d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "synset_frequencies.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9661a041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Synset: car.n.01 - Frequency: 71\n",
      "2. Synset: car.n.02 - Frequency: 2\n",
      "3. Synset: car.n.03 - Frequency: 0\n",
      "4. Synset: car.n.04 - Frequency: 0\n",
      "5. Synset: cable_car.n.01 - Frequency: 0\n"
     ]
    }
   ],
   "source": [
    "for i, (synset, frequency) in enumerate(synset_frequencies, start=1):\n",
    "    print(f\"{i}. Synset: {synset.name()} - Frequency: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e1fd4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/moinul/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/moinul/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27046ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = \"Students feel unhappy today about the class today\"\n",
    "T2 = \"Many students felt concepts of class test relevant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c567e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "\n",
    "words_T1 = word_tokenize(T1)\n",
    "words_T2 = word_tokenize(T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d899b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords removal\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words_T1 = [word.lower() for word in words_T1 if word.lower() not in stop_words]\n",
    "filtered_words_T2 = [word.lower() for word in words_T2 if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fd2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_words_T1 = [stemmer.stem(word) for word in filtered_words_T1]\n",
    "stemmed_words_T2 = [stemmer.stem(word) for word in filtered_words_T2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a133eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the tokens back into sentence\n",
    "\n",
    "processed_T1 = \" \".join(stemmed_words_T1)\n",
    "processed_T2 = \" \".join(stemmed_words_T2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4317be5",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Now consider two sentences T1 and T2, each constituted with a set of tokens. For this purpose, study expression (1) of the aforementioned Mihalcea et al.’s paper above (see below).  You can check with a potential implementation available at https://nlpforhackers.io/wordnet-sentence-similarity/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c840370",
   "metadata": {},
   "source": [
    "### Mihalcea Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "e5094776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mihalcea's Similarity: 0.3212801648924751\n"
     ]
    }
   ],
   "source": [
    "#Mihalcea's Similarity\n",
    "import math\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def mihalcea_similarity(tokens_T1, tokens_T2):\n",
    "    similarity_score = 0\n",
    "    \n",
    "    word_counts = {}\n",
    "    for doc in [tokens_T1, tokens_T2]:\n",
    "        for word in doc:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "    idf_values = {}\n",
    "    total_docs = len(tokens_T1) + len(tokens_T2)\n",
    "    \n",
    "    for word, count in word_counts.items():\n",
    "        idf_values[word] = math.log(total_docs / (count + 1)) \n",
    "\n",
    "    def max_similarity(word1, word2):\n",
    "        max_sim = 0\n",
    "        for synset1 in wn.synsets(word1):\n",
    "            for synset2 in wn.synsets(word2):\n",
    "                sim = synset1.wup_similarity(synset2)\n",
    "                if sim is not None and sim > max_sim:\n",
    "                    max_sim = sim\n",
    "        return max_sim\n",
    "    \n",
    "    for word in set(tokens_T1):\n",
    "        max_sim = 0\n",
    "        for word2 in tokens_T2:  # Iterate over tokens_T2\n",
    "            max_sim = max(max_sim, max_similarity(word, word2))\n",
    "        similarity_score += (max_sim * idf_values.get(word, 0))\n",
    "\n",
    "    for word in set(tokens_T2):\n",
    "        max_sim = 0\n",
    "        for word2 in tokens_T1:  # Iterate over tokens_T1\n",
    "            max_sim = max(max_sim, max_similarity(word, word2))\n",
    "        similarity_score += (max_sim * idf_values.get(word, 0))\n",
    "\n",
    "    denominator = sum(idf_values.get(word, 0) for word in set(tokens_T1)) + sum(idf_values.get(word, 0) for word in set(tokens_T2))\n",
    "\n",
    "    similarity_score /= (2 * denominator)\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "similarity = mihalcea_similarity(words_T1, words_T2)\n",
    "print(\"Mihalcea's Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a542d3",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Start with sentences: T1: “Students feel unhappy today about the class today”. T2: ”Many students felt concepts of class test relevant”,  and study the influence of various preprocessing (stopword removal, stemming) on the result of the sentence-to-sentence similarity above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee5a40",
   "metadata": {},
   "source": [
    "### TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c29501f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF vectorization\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#for original sentences\n",
    "tfidf_matrix_org = vectorizer.fit_transform([T1, T2])\n",
    "\n",
    "#for preprocessed sentences\n",
    "tfidf_matrix_pre = vectorizer.fit_transform([processed_T1, processed_T2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2957c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating cosine similarity\n",
    "\n",
    "#for original sentences\n",
    "cosine_sim_org = cosine_similarity(tfidf_matrix_org[0], tfidf_matrix_org[1])[0][0]\n",
    "\n",
    "#for preprocessed sentences\n",
    "cosine_sim_pre = cosine_similarity(tfidf_matrix_pre[0], tfidf_matrix_pre[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f9e08826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence 1: Students feel unhappy today about the class today\n",
      "Original Sentence 2: Many students felt concepts of class test relevant\n",
      "Cosine Similarity: 0.12735952979479354\n",
      "\n",
      "\n",
      "Processed Sentence 1: student feel unhappi today class today\n",
      "Processed Sentence 2: mani student felt concept class test relev\n",
      "Cosine Similarity: 0.15592892548708365\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Sentence 1:\", T1)\n",
    "print(\"Original Sentence 2:\", T2)\n",
    "print(\"Cosine Similarity:\", cosine_sim_org)\n",
    "print('\\n')\n",
    "print(\"Processed Sentence 1:\", processed_T1)\n",
    "print(\"Processed Sentence 2:\", processed_T2)\n",
    "print(\"Cosine Similarity:\", cosine_sim_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a373bf",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Implement a program that calculates the sentence-to-sentence similarity as the result of the FuzzyWuzzy score of comparison of string of both sentences, after initial preprocessing and lemmatization using wordnet lemmatizer. Calculate the new similarity score between sentence T1 and T2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294aa223",
   "metadata": {},
   "source": [
    "### FuzzyWuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e4ef4318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /Users/moinul/anaconda3/lib/python3.11/site-packages (0.18.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "268e81c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Sentence 1: student feel unhappy today class today\n",
      "Processed Sentence 2: many student felt concept class test relevant\n",
      "FuzzyWuzzy Similarity Score: 0.58\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "#Lemmatization using WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words_T1 = [lemmatizer.lemmatize(word) for word in filtered_words_T1]\n",
    "lemmatized_words_T2 = [lemmatizer.lemmatize(word) for word in filtered_words_T2]\n",
    "\n",
    "# Combining the preprocessed sentence\n",
    "processed_T1 = \" \".join(lemmatized_words_T1)\n",
    "processed_T2 = \" \".join(lemmatized_words_T2)\n",
    "\n",
    "# Calculate FuzzyWuzzy similarity score\n",
    "similarity_score = fuzz.token_set_ratio(processed_T1, processed_T2) / 100.00\n",
    "\n",
    "print(\"Processed Sentence 1:\", processed_T1)\n",
    "print(\"Processed Sentence 2:\", processed_T2)\n",
    "print(\"FuzzyWuzzy Similarity Score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4abcb",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Now consider a new sentence-to-sentence similarity where the similarity score is calculated as the cosine similarity of embedding vectors of the two sentences and where the embedding vector of each sentence is the average of FastText embedding vector of each word constituting the sentence prior to any pre-processing stage. Write a program that implements this similarity metric and compute the sentence-to-sentence similarity of T1 and T2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e1d56",
   "metadata": {},
   "source": [
    "### FastText Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2c806c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11>=2.2 (from fasttext)\n",
      "  Obtaining dependency information for pybind11>=2.2 from https://files.pythonhosted.org/packages/06/55/9f73c32dda93fa4f539fafa268f9504e83c489f460c380371d94296126cd/pybind11-2.11.1-py3-none-any.whl.metadata\n",
      "  Using cached pybind11-2.11.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/moinul/anaconda3/lib/python3.11/site-packages (from fasttext) (68.0.0)\n",
      "Requirement already satisfied: numpy in /Users/moinul/anaconda3/lib/python3.11/site-packages (from fasttext) (1.24.3)\n",
      "Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp311-cp311-macosx_14_0_arm64.whl size=291526 sha256=fadfb94d7fac60f6f35a209d94579dac4aeed08cd055804462721492185ebbb1\n",
      "  Stored in directory: /Users/moinul/Library/Caches/pip/wheels/12/89/c9/c932d04c4dd65abe347bbb3e6f7668688753cbc585305ad8b7\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37dd2b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f3de5d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of Sentence Embeddings: 0.6717617\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Calcuting average for each sentence using Fasttext embeddings\n",
    "def get_average_embedding(sentence, model):\n",
    "    embeddings = []\n",
    "    for word in sentence:\n",
    "        if word in model:\n",
    "            embeddings.append(model[word])\n",
    "    if len(embeddings) > 0:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.get_dimension())\n",
    "\n",
    "embedding_T1 = get_average_embedding(words_T1, ft)\n",
    "embedding_T2 = get_average_embedding(words_T2, ft)\n",
    "\n",
    "# Reshape the embeddings for cosine similarity calculation\n",
    "embedding_T1 = embedding_T1.reshape(1, -1)\n",
    "embedding_T2 = embedding_T2.reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity between the sentence embeddings\n",
    "similarity_score = cosine_similarity(embedding_T1, embedding_T2)[0][0]\n",
    "\n",
    "print(\"Cosine Similarity of Sentence Embeddings:\", similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40f5a49",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "\n",
    "Repeat the above process when using Glove, word2vec embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf70720",
   "metadata": {},
   "source": [
    "### GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f4c5502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity using GloVe embeddings: 0.7461909\n"
     ]
    }
   ],
   "source": [
    "#Loading GloVe word vectors\n",
    "glove_embeddings = {}\n",
    "\n",
    "with open('glove.6B.300d.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        word = parts[0]\n",
    "        embedding = np.array(parts[1:], dtype=np.float32)\n",
    "        glove_embeddings[word] = embedding\n",
    "\n",
    "\n",
    "#Calcuting average for each sentence using GloVe embeddings\n",
    "def get_average_embedding(sentence, embeddings):\n",
    "    embeddings_list = [embeddings[word] for word in sentence if word in embeddings]\n",
    "    if embeddings_list:\n",
    "        return np.mean(embeddings_list, axis=0)\n",
    "    else:\n",
    "        return np.zeros(300)\n",
    "\n",
    "embedding_T1 = get_average_embedding(words_T1, glove_embeddings)\n",
    "embedding_T2 = get_average_embedding(words_T2, glove_embeddings)\n",
    "\n",
    "# Reshape the embeddings for cosine similarity calculation\n",
    "embedding_T1 = embedding_T1.reshape(1, -1)\n",
    "embedding_T2 = embedding_T2.reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_score = cosine_similarity(embedding_T1, embedding_T2)[0][0]\n",
    "\n",
    "print(\"Cosine Similarity using GloVe embeddings:\", similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a58cd9e",
   "metadata": {},
   "source": [
    "### Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c23822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/moinul/anaconda3/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/moinul/anaconda3/lib/python3.11/site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/moinul/anaconda3/lib/python3.11/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/moinul/anaconda3/lib/python3.11/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /Users/moinul/anaconda3/lib/python3.11/site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in /Users/moinul/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: pyfume in /Users/moinul/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/moinul/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/moinul/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Requirement already satisfied: simpful in /Users/moinul/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.11.0)\n",
      "Requirement already satisfied: fst-pso in /Users/moinul/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/moinul/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in /Users/moinul/anaconda3/lib/python3.11/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c8c1b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95512f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity using Word2Vec embeddings: 0.6702926\n"
     ]
    }
   ],
   "source": [
    "#Calcuting average for each sentence using Word2Vec embeddings\n",
    "def get_average_embedding(sentence, model):\n",
    "    embeddings = []\n",
    "    for word in sentence:\n",
    "        if word in model:\n",
    "            embeddings.append(model[word])\n",
    "    if len(embeddings) > 0:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "embedding_T1 = get_average_embedding(words_T1, w2v_model)\n",
    "embedding_T2 = get_average_embedding(words_T2, w2v_model)\n",
    "\n",
    "# Reshape the embeddings for cosine similarity calculation\n",
    "embedding_T1 = embedding_T1.reshape(1, -1)\n",
    "embedding_T2 = embedding_T2.reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_score = cosine_similarity(embedding_T1, embedding_T2)[0][0]\n",
    "\n",
    "print(\"Cosine Similarity using Word2Vec embeddings:\", similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45799a",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Consider the Quora question-answer pair in Question Pairs Dataset. Write a program that evaluate the sentence-to-sentence similarity using the five methods above (**Mihalacea, FuzzyWuzzy, FastText, Word2Vec, GloVe**) and calculate the score over all pairs, testing pairs. Compare your result with some of results reported in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "bf5b24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "0e668b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('questions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "7390cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df.sample(3000,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "6a06f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "new_df['Q1_tokens'] = new_df['question1'].apply(tokenize)\n",
    "new_df['Q2_tokens'] = new_df['question2'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "2f239909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mihalcea's Similary\n",
    "\n",
    "def mihalcea_similarity(tokens_T1, tokens_T2):\n",
    "    similarity_score = 0\n",
    "    \n",
    "    word_counts = {}\n",
    "    for doc in [tokens_T1, tokens_T2]:\n",
    "        for word in doc:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "    idf_values = {}\n",
    "    total_docs = len(tokens_T1) + len(tokens_T2)\n",
    "    \n",
    "    for word, count in word_counts.items():\n",
    "        idf_values[word] = math.log(total_docs / (count + 1)) \n",
    "\n",
    "    def max_similarity(word1, word2):\n",
    "        max_sim = 0\n",
    "        for synset1 in wn.synsets(word1):\n",
    "            for synset2 in wn.synsets(word2):\n",
    "                sim = synset1.wup_similarity(synset2)\n",
    "                if sim is not None and sim > max_sim:\n",
    "                    max_sim = sim\n",
    "        return max_sim\n",
    "    \n",
    "    for word in set(tokens_T1):\n",
    "        max_sim = 0\n",
    "        for word2 in tokens_T2:  # Iterate over tokens_T2\n",
    "            max_sim = max(max_sim, max_similarity(word, word2))\n",
    "        similarity_score += (max_sim * idf_values.get(word, 0))\n",
    "\n",
    "    for word in set(tokens_T2):\n",
    "        max_sim = 0\n",
    "        for word2 in tokens_T1:  # Iterate over tokens_T1\n",
    "            max_sim = max(max_sim, max_similarity(word, word2))\n",
    "        similarity_score += (max_sim * idf_values.get(word, 0))\n",
    "\n",
    "    denominator = sum(idf_values.get(word, 0) for word in set(tokens_T1)) + sum(idf_values.get(word, 0) for word in set(tokens_T2))\n",
    "\n",
    "    similarity_score /= (2 * denominator)\n",
    "    \n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "76d9274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FuzzyWuzzy Similarity\n",
    "\n",
    "def fuzzywuzzy_similarity(q1,q2):\n",
    "    return fuzz.token_set_ratio(q1, q2) / 100.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "9d8c3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FastText\n",
    "\n",
    "def fasttext_similarity(q1, q2):\n",
    "    def get_average_embedding(sentence, model):\n",
    "        embeddings = []\n",
    "        for word in sentence:\n",
    "            if word in model:\n",
    "                embeddings.append(model[word])\n",
    "        if len(embeddings) > 0:\n",
    "            return np.mean(embeddings, axis=0)\n",
    "        else:\n",
    "            return np.zeros(model.get_dimension())\n",
    "\n",
    "    embedding_T1 = get_average_embedding(q1, ft)\n",
    "    embedding_T2 = get_average_embedding(q2, ft)\n",
    "\n",
    "    # Reshape the embeddings for cosine similarity calculation\n",
    "    embedding_T1 = embedding_T1.reshape(1, -1)\n",
    "    embedding_T2 = embedding_T2.reshape(1, -1)\n",
    "\n",
    "    # Calculate cosine similarity between the sentence embeddings\n",
    "    similarity_score = cosine_similarity(embedding_T1, embedding_T2)[0][0]\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "609c5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GloVe\n",
    "glove_embeddings = {}\n",
    "with open('glove.6B.300d.txt', 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            embedding = np.array(parts[1:], dtype=np.float32)\n",
    "            glove_embeddings[word] = embedding\n",
    "\n",
    "def glove_similarity(q1, q2):           \n",
    "    def get_average_embedding(sentence, embeddings):\n",
    "        embeddings_list = [embeddings[word] for word in sentence if word in embeddings]\n",
    "        if embeddings_list:\n",
    "            return np.mean(embeddings_list, axis=0)\n",
    "        else:\n",
    "            return np.zeros(300)\n",
    "    \n",
    "    q1_str = ' '.join(q1)\n",
    "    q2_str = ' '.join(q2)\n",
    "    \n",
    "    embedding_T1 = get_average_embedding(q1_str.split(), glove_embeddings)\n",
    "    embedding_T2 = get_average_embedding(q2_str.split(), glove_embeddings)\n",
    "\n",
    "\n",
    "    embedding_T1 = embedding_T1.reshape(1, -1)\n",
    "    embedding_T2 = embedding_T2.reshape(1, -1)\n",
    "\n",
    "    similarity_score = cosine_similarity(embedding_T1, embedding_T2)[0][0]\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "d6dd3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec\n",
    "\n",
    "def word2vec_similarity(q1, q2):\n",
    "    def get_average_embedding(sentence, model):\n",
    "        embeddings = []\n",
    "        for word in sentence:\n",
    "            if word in model:\n",
    "                embeddings.append(model[word])\n",
    "        if len(embeddings) > 0:\n",
    "            return np.mean(embeddings, axis=0)\n",
    "        else:\n",
    "            return np.zeros(model.vector_size)\n",
    "\n",
    "    embedding_T1 = get_average_embedding(q1, w2v_model)\n",
    "    embedding_T2 = get_average_embedding(q2, w2v_model)\n",
    "\n",
    "    # Reshape the embeddings for cosine similarity calculation\n",
    "    embedding_T1 = embedding_T1.reshape(1, -1)\n",
    "    embedding_T2 = embedding_T2.reshape(1, -1)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(embedding_T1, embedding_T2)[0][0]\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "daf2567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Similarity Scores of all 5 Methods\n",
    "\n",
    "def calculate_similarity_scores(q1, q2):\n",
    "    similarity_scores = []\n",
    "    \n",
    "#     mihalcea_score = mihalcea_similarity(q1, q2)\n",
    "#     fuzzywuzzy_score = fuzzywuzzy_similarity(q1, q2)\n",
    "        \n",
    "    for i in range(len(q1)):\n",
    "        q1_tokens = q1.iloc[i]  # Get the list of tokens for the current row\n",
    "        q2_tokens = q2.iloc[i]  # Get the list of tokens for the current row\n",
    "        mihalcea_score = mihalcea_similarity(q1_tokens, q2_tokens)\n",
    "        fuzzywuzzy_score = fuzzywuzzy_similarity(q1_tokens, q2_tokens)\n",
    "        fasttext_score = fasttext_similarity(q1_tokens, q2_tokens)\n",
    "        glove_score = glove_similarity(q1_tokens, q2_tokens)\n",
    "        word2vec_score = word2vec_similarity(q1_tokens, q2_tokens)\n",
    "        similarity_scores.append([mihalcea_score, fuzzywuzzy_score, fasttext_score, glove_score, word2vec_score])\n",
    "    return pd.DataFrame(similarity_scores, columns=['Mihalcea','FuzzyWuzzy','FastText','GloVe', 'Word2Vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "69feb4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mihalcea</th>\n",
       "      <th>FuzzyWuzzy</th>\n",
       "      <th>FastText</th>\n",
       "      <th>GloVe</th>\n",
       "      <th>Word2Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.221460</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.862519</td>\n",
       "      <td>0.878094</td>\n",
       "      <td>0.814089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.224384</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.852516</td>\n",
       "      <td>0.910222</td>\n",
       "      <td>0.714067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.252014</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.998917</td>\n",
       "      <td>0.994769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.316605</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.928288</td>\n",
       "      <td>0.915257</td>\n",
       "      <td>0.811866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305664</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.878342</td>\n",
       "      <td>0.927221</td>\n",
       "      <td>0.878093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.204544</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.822965</td>\n",
       "      <td>0.796477</td>\n",
       "      <td>0.536979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.309962</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.869877</td>\n",
       "      <td>0.903219</td>\n",
       "      <td>0.823236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.329448</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.977504</td>\n",
       "      <td>0.985161</td>\n",
       "      <td>0.962474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.269433</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.844196</td>\n",
       "      <td>0.915376</td>\n",
       "      <td>0.745623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.262219</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.891905</td>\n",
       "      <td>0.924728</td>\n",
       "      <td>0.773597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mihalcea  FuzzyWuzzy  FastText     GloVe  Word2Vec\n",
       "0     0.221460        0.85  0.862519  0.878094  0.814089\n",
       "1     0.224384        0.37  0.852516  0.910222  0.714067\n",
       "2     0.252014        0.99  0.999985  0.998917  0.994769\n",
       "3     0.316605        0.89  0.928288  0.915257  0.811866\n",
       "4     0.305664        0.79  0.878342  0.927221  0.878093\n",
       "...        ...         ...       ...       ...       ...\n",
       "2995  0.204544        0.53  0.822965  0.796477  0.536979\n",
       "2996  0.309962        0.68  0.869877  0.903219  0.823236\n",
       "2997  0.329448        0.84  0.977504  0.985161  0.962474\n",
       "2998  0.269433        0.63  0.844196  0.915376  0.745623\n",
       "2999  0.262219        0.64  0.891905  0.924728  0.773597\n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores = calculate_similarity_scores(new_df['Q1_tokens'], new_df['Q2_tokens'])\n",
    "similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49014879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
